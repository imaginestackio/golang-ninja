# Recursion

In this chapter, we are going to talk about recursion. This is a topic that all programmers encounter sooner or later, as it’s not exclusive to the functional paradigm. Any language in which you can express function calls allows you to express functions that are recursive in nature. For many, it is not a topic that is difficult to understand at first. In functional programming languages such as Haskell, recursion takes center stage.

As such, this chapter is dedicated to understanding exactly how recursion works, including what the performance implications are of doing so, and what the limits of recursion are in Go. We’ll also take a look at some handy constructs for dealing with recursion using functions as first-class citizens.

In this chapter, we will cover these main topics:

-   What recursion means
-   Why use recursive functions?
-   When and how to use recursive functions
-   Leveraging functions as first-class citizens to write recursive functions
-   Understanding the limitations of recursive functions in Go
-   Understanding Tail-Recursion and compiler optimizations

What we will learn in this chapter will set us up for success when talking about the Continuation-Passing style and fluent programming in later chapters.

Just Imagine

# Technical requirements

For this chapter, you should use any version of Go at or above 1.18. All the code can be found on GitHub at [https://github.com/ImagineDevOps DevOps/Functional-Programming-in-Go./tree/main/Chapter7](https://github.com/ImagineDevOps DevOps/Functional-Programming-in-Go./tree/main/Chapter7).

Just Imagine

# What is recursion?

Simply put, a recursive function is a function that calls itself. In practice, this means that the following function is an example of a recursive function:

```markup
func recursive() {
    recursive()
}
```

In this example, if the user would call the function “recursive,” all it would do would call itself ad infinitum. Effectively, this is an infinite loop and not the most useful function. To make recursive functions useful, we can extend our definition of a recursive function a bit further by setting up two rules:

-   A function must have a condition on which to call itself (recurse)
-   A function must have a condition on which it returns _without_ calling itself

The first condition just states that given a function, `X`, at some point in the function’s body, `X` will be called again. The second condition is that there exists a case for which the function, `X`, returns from the function without calling itself. This second condition is often called the _base case_ of the recursive function.

To understand what this looks like, let’s implement a classical mathematical operation that lends itself well to recursion, namely the factorial function. The factorial function is defined as a function that, given an input, _N_, multiplies all the numbers of _N_ down to 1; for example:

```markup
Fact(5) = 5 * 4 * 3 * 2 * 1
```

To see why this is a recursive function, we can show that the result of calling `Fact(5)` is the result of calling 5 multiplied by the result of `Fact(4)`. Thus, if we write this out, we will get the following:

```markup
Fact(5) = 5 * Fact(4) = 5 * 24 = 120
Fact(4) = 4 * Fact(3) = 4 * 6 = 24
Fact(3) = 3 * Fact(2) = 3 * 2 = 6
Fact(2) = 2 * Fact(1) = 2 * 1 = 2
Fact(1) = 1 * Fact(0) = 1 * 1
Fact(0) = 1
```

Notice that in this example, the factorial of 0 is simply 1. This is defined as our base case; when a value of 0 is passed to our function, we simply return the integer value 1. However, in all other input cases, we are multiplying the input number with the output of calling the factorial function with `input-1`.

If we turn this into Go code, we will get the following:

```markup
func main() {
    fmt.Println(Fact(5))
}
func Fact(input int) int {
    if input == 0 {
        return 1
    }
    return input * Fact(input-1)
}
```

If this is the first time you’ve seen recursion in a while, it may take you a few minutes to wrap your head around what is happening here. One way to think about this is that each function call to `Fact` pushes a function onto our stack. When all functions are pushed to the stack, they are evaluated from top to bottom, and each lower level of the stack can use the result from what came above it:

![Figure 7.1: Recursive function calls and stack allocation](https://static.packt-cdn.com/products/9781801811163/graphics/image/Figure_7.1_B18771.jpg)

Figure 7.1: Recursive function calls and stack allocation

Thinking about recursion in this stack-based way will help us understand the examples and pitfalls of recursion later in this chapter. But before we get to that, let’s look at when you might want to opt for writing a recursive function instead of an iterative one and why functional languages typically favor recursion.

Just Imagine

# Why do functional languages favor recursion?

Before we discuss when to use recursive functions in Go, let’s answer the question of why functional languages seem to prefer recursion rather than `for` loops. The best answer for this is that recursion is inherently purer than iterative solutions. Although each program that can be expressed recursively can also be expressed iteratively, iterative solutions need to maintain more state than recursive solutions.

Our simple factorial example highlights this when we write an iterative implementation:

```markup
func factorial(n int) int {
    result := 1
    for i := 1; i <= n; i++ {
        result = result * i
    }
    return result
}
```

In this factorial implementation, we are mutating the “result” in each iteration of the `for` loop. It is a well-contained mutation as it does not escape the function itself, but it’s a mutating state, nonetheless. Meanwhile, our pure recursive example never mutates the state. Rather than mutating the state, it returns a **new** value by combining an input parameter with the output of a function call:

```markup
return input * Fact(input-1)
```

As a general rule, recursion allows us to create new functions with copied states, make changes to the copies, and return the result, all without mutating a value in the recursive call itself. This means that changes to the program state are contained within each stack frame.

Recursive state changes in Go

In Go and other non-pure languages, it is possible to mutate the state in recursive function calls. In such languages, recursion does not guarantee the immutability of the state but it does make it easier to write immutable implementations.

Just Imagine

# When to use recursive functions

To understand when to use a recursive function, we have to talk about the main trade-offs between iterative and recursive functions. But before we get to that, let’s start by saying that anything that can be implemented iteratively can also be implemented recursively. As such, each function that has a `for` statement in Go can be replaced by an equivalent function that uses a recursive function call in place of the `for` loop.

However, we might not always want to do so. The two main disadvantages of recursive functions are that they typically have greater time and space requirements. Calling a function multiple times creates multiple stack frames. These stack frames use up part of the working memory of our programs. Typically, each frame will contain a copy of the data from the frame below it (in a recursive function), which means that in the earlier Factorial example, each function call uses a similar amount of memory as the function that came before it. However, all these stack frames, at some point, are alive at the same time. A recursive call stack does not pop the stack until the final recursive call is completed. Hence, in _Figure 7__.1_, we can see that all stacks are added on top of each other, and are then evaluated from top to bottom (**Last-In, First-Out**, or **LIFO**). Had we written the same function iteratively, we would only have had one function on the call stack.

The second limitation of recursive functions is that they are typically slower than their iterative counterparts. This is mostly because function calls are expensive operations as far as programming language features go. In light of what we have just learned about the call stack, this makes sense. Each function call has to copy over memory to a new location, perform the core algorithm, and then copy it all over again for the next recursive call.

So, why would we want to still use recursive functions? Well, although these limitations are important, our main goal is to achieve code readability and maintainability. Recursion, once mastered, can make programs not only easier to write but also easier to understand. Problems that involve traversing over graphs or trees easily lend themselves to recursive functions (as these data structures are recursive data structures themselves). An overarching theme of this book is that we’ll trade off performance for the convenience of both you, the programmer, and later readers of the code.

As a side note, in languages such as Haskell, writing recursive functions involves less syntax overhead than in Go – especially when combined with a concept known as _pattern matching_. Without diverging too much from the core content of this chapter, let’s quickly look at the factorial implementation in Haskell:

```markup
factorial :: Integral -> Integral
factorial 0 = 1
factorial n = n * factorial (n-1)
```

The preceding snippet is a full implementation of the Factorial function. Notice that it reads almost like a more mathematical description of the problem. This makes writing the recursive solution more appealing. In addition, Haskell also performs compiler-level optimizations for handling recursive functions. We’ll briefly look at one such optimization, Tail-Call optimization, later in this chapter.

## Iterating over trees

To demonstrate the preceding assumption that some code is easier to write recursively rather than functionally, let’s take a look at an example of iterating over a tree. Trees are recursive data structures, and as such should lend themselves to this implementation. For simplicity, let’s assume we have a tree that stores integers; the actual values don’t matter as much. We’ll construct a tree that looks like this:

![Figure 7.2: Example of a (binary) tree](https://static.packt-cdn.com/products/9781801811163/graphics/image/Figure_7.2_B18771.jpg)

Figure 7.2: Example of a (binary) tree

The actual values of each node don’t matter, but let’s say we want to find the sum of all nodes. In plain English, what we have to do is get the value of each node. Then, for each node, we need to figure out if it has children. If so, we add the value of the child to our running sum. Next, for all of those children, we figure out if they have children, and if so, also add their values to our running sum. We do this until we have seen all the nodes.

To demonstrate this, let’s create a data structure that represents our tree. The type declaration itself is straightforward: we have a node that contains a value, and each node has a pointer to a left and right child. These children are optionally present:

```markup
type node struct {
        value int
        left  *node
        right *node
}
```

With this struct set up, let’s also introduce an actual tree on which we can demonstrate our example functions later in this chapter. We can create this as a package-level object in a `var` block. We’ll model the tree shown in _Figure 7__.2_:

```markup
var (
        ExampleTree = &node{
                value: 1,
                left: &node{
                        value: 2,
                        left: &node{
                                value: 3,
                        },
                        right: &node{
                                value: 4,
                        },
                },
                right: &node{
                        value: 5,
                },
        }
)
```

Before we write this as a recursive solution, let’s write this as an iterative solution using a normal `for` loop.

### Iteratively solving tree problems using a for loop

We need to introduce some additional data structures before we can make this work. The data structure that we will use here is a `Queue`. For each node that we visit, we will add the node’s value to our sum. For each child of the node, we will add the child to our `Queue`. We will keep doing this until our `Queue` is empty. As a starting value, we will add the root of our tree to our `Queue` to kickstart the entire process.

One important disclaimer is that, at the time of writing, Go does not ship with an easy-to-use, out-of-the-box queue implementation. However, Go does include buffered channels out of the box. We can use buffered channels to get queue-like behavior, which is what we will be doing to demonstrate this. The main properties to get queue-like behavior are as follows:

-   Being able to push an element to the queue
-   Being able to pop (remove) an element from the queue in LIFO style

You could use a slice to get this behavior, but even that requires some overhead for managing the slice and it’s not the most performant implementation. A real queue would offer constant-time addition and removal. For that matter, perhaps buffered channels are doing this in an optimized way under the hood, but further exploration of that is outside the scope of this book. One necessary assumption we have to make, however, is that we know the size of our queue beforehand.

In a real-world scenario, this is often not the case. You could pass a best-effort estimation for the queue size to the buffered channel, but this seems error-prone. For didactic purposes and not to distract from the essence of the algorithm, we will accept those assumptions for now. With this disclaimer out of the way, let’s learn how to implement a function to get the sum of all the nodes in a tree iteratively:

```markup
func sumIterative(root *node) int {
        queue := make(chan *node, 10)
        queue <- root
        var sum int
        for {
                select {
                case node := <-queue:
                        sum += node.value
                        if node.left != nil {
                                queue <- node.left
                        }
                        if node.right != nil {
                                queue <- node.right
                        }
                default:
                        return sum
                }
        }
}
```

In this example, we are adding a bit of additional overhead since we are managing our queue behavior using buffered channels. However, the core algorithm is the same. You could imagine saving some lines of code by not having a `select` block when using a real queue implementation though.

Next up, let’s take a look at how we can solve this problem recursively.

### Recursively solving tree problems

When thinking about this problem recursively, it becomes much clearer and easier to implement.

Remember from our factorial example that we are adding calls to our stack frame until we encounter a base case for which we can return a value without calling the function itself. The base case for this implementation is an absent node (nil pointer). Such a node will return a value of 0 as there is no sum to be made. For each other node, we return the sum of its value, along with the sum of values for all children. Visualizing this like a stack, we are adding frames to our stack from bottom to top, but evaluating from top to bottom, aggregating the sum as we go along:

```markup
func sumRecursive(node *node) int {
        if node == nil {
                return 0
        }
        return node.value + sumRecursive(node.left) +
            sumRecursive(node.right)
}
```

This recursive code is one way to solve this problem without too much overhead. It is a more readable version of the iterative solution, and our code is closer to our intention. How does the recursive solution relate to what we have learned about functional programming so far?

In functional programming languages, you want to tell the computer _what_ to solve instead of _how_ to solve it. When you are writing loops manually, you are firmly in the domain of the how rather than the what of a given problem. In addition, our recursive solution is not mutating state anywhere, which brings us closer to an ideal function in the world of functional programming.

Functional languages and loops

While recursion is preferred in functional languages, many do offer constructs for creating manual loops as well. That said, they often offer compiler optimizations for recursive functions, which makes them an even more attractive option to solve problems.

Just Imagine

# Recursion and functions as first-class citizens

What we have seen so far in this chapter can be applied to any language that has function calls, even in languages that stick more firmly to the object-oriented domain. In this section, we’ll learn how to leverage some of the concepts of functional and multi-paradigm languages that make recursion easier to write and manage.

One of the most useful features I’ve found is to combine recursion with closures. To give an example of when this comes in handy, imagine working recursively on a data structure and having to keep some state tracked. Rather than tracking the state at the package level, or complicating the recursive function to keep the state tracked in the recursing functions, _we can create an outer function that is not recursive and then use a recursive inner function_. Let’s demonstrate this with an example to clear up some potential confusion.

Using the same tree as in the previous example, let’s write a function to find the maximum value of a node in the tree. To achieve this, we need a way to track what the maximum value is, which we’ve seen so far. One option to achieve this is by tracking the state in a global variable outside of our recursive function. This is messy but would work. For example, the following code traverses the tree and uses a global variable to track what the maximum encountered value is as follows:

```markup
var maximum = 0
func MaxGlobalVariable(node *node) {
        if node == nil {
                return
        }
        if node.value > maximum {
                maximum = node.value
        }
        MaxGlobalVariable(node.left)
        MaxGlobalVariable(node.right)
}
func main() {
        maximum = int(math.MinInt)
        MaxGlobalVariable(ExampleTree)
        fmt.Println(maximum)
}
```

The preceding code is not the ideal solution. First of all, using global variables to track any state should be discouraged. It would cause major headaches when writing multithreaded code, and if you’d forget to reset the global variable before a run of the recursive function. The outcome would be unreliable, even for single-threaded runs.

Another much better approach is to track the current maximum value as part of each recursive call. This is achieved by extending the function signature so that it includes the integer value that we are tracking, as shown in the following code:

```markup
func.maxInline(node *node,
    maxValue int) int {
        if node == nil {
                return maxValue
        }
        if node.value > maxValue {
                maxValue = node.value
        }
        maxLeft := maxInline(node.left, maxValue)
        maxRight := maxInline(node.right, maxValue)
        if maxLeft > maxRight {
                return maxLeft
        }
        return maxRight
}
```

Here, we are tracking the maximum value in the `maxValue` variable, which is passed in each recursive call. Then, in each call, we are continuing the recursive call downwards with the maximum value between `node.value` and `maxValue`. We end the calls by comparing the left and right-hand sides of the tree and returning the max of both sides.

This is probably the cleanest way of writing the recursive function itself if we ignore what the code of the caller looks like. If we want to call the `maxInline` function, our calling functions will look like this:

```markup
func main() {
        fmt.Println(maxInline(ExampleTree, 0))
}
```

In the function call to `maxInline`, we are effectively leaking an implementation detail to the caller. The caller has to pass the initial starting value to our recursive function. This is rather messy, and for more complex functions, we can’t necessarily expect the caller to know what the appropriate value is. Ideally, we don’t leak such state details to our callers. Traditional object-oriented languages solve this problem by exposing a public non-recursive function that calls a private recursive function with the state appended. Modeling this in Go, we get the following:

```markup
func main() {
        fmt.Println(MaxInline(ExampleTree))
}
func MaxInline(root *node) int {
        return maxInline(root, 0)
}
func maxInline(node *node, maxValue int) int {
        if node == nil {
                return maxValue
        }
        if node.value > maxValue {
                maxValue = node.value
        }
        maxLeft := maxInline(node.left, maxValue)
        maxRight := maxInline(node.right, maxValue)
        if maxLeft > maxRight {
                return maxLeft
        }
        return maxRight
}
```

Here, we have created a public `MaxInline` function that does not expose the internal mechanism for `maxInline`. The caller only needs to provide the root node to the public function. This function will then call the private `maxInline` function with the appropriate starting state. This pattern is incredibly common in object-oriented languages, and if those languages don’t support first-class functions, this is the right way to go about it.

However, in Go, we can do better. The main issue with the preceding approach is that you are still cluttering the package-private space with a function anyone working in the package can use. This might be desired behavior, but not always. One way to work around this is by encapsulating the recursive function _within_ the non-recursive function. In this way, we can track the state inside the non-recursive function, which is accessible to the recursive inner function.

The following implementation does exactly that:

```markup
func Max(root *node) int {
        currentMax := math.MinInt
        var inner func(node *node)
        inner = func(node *node) {
                if node == nil {
                        return
                }
                if node.value > currentMax {
                        currentMax = node.value
                }
                inner(node.left)
                inner(node.right)
        }
        inner(root)
        return currentMax
}
```

Let’s take a look at what is happening here. First, note that our `Max` function is not recursive itself. This allows us to perform some operations that we know will only happen once per call to `Max`. For example, this is a great place to log activity, add metrics for performance, or add some state, as we are doing here. In our case, we’re creating a variable called `currentMax`. This variable will keep track of what the maximum value is that we’ve encountered.

Next, we are creating a variable called `inner` of the `func(node *node)` type. This is an important step. We’re not creating the function in-line immediately; first, we need to set up the variable without an implementation attached to it. The reason why we are doing this is so that we can refer to the `inner` variable inside an anonymous function.

The next step is to instantiate this `inner` function. If we tie that block together, we get this:

```markup
var inner func(node *node)
inner = func(node *node) {
        if node == nil {
                return
        }
        if node.value > currentMax {
                currentMax = node.value
        }
        inner(node.left)
        inner(node.right)
}
```

This shows how we are calling `inner(node.left)` and `inner(node.right)` from within the `inner` function itself. This would not work if we did not define the function first without instantiating. In other words, the following code would not work:

```markup
inner := func(node *node) {
   if node == nil {
      return
   }
   if node.value > currentMax {
      currentMax = node.value
   }
   inner(node.left)
   inner(node.right)
}
```

It’s a seemingly small change, but it would break our function. After all, how could we refer to `inner` if the compiler hadn’t yet compiled the function that you are trying to create?

The last step of our code is to call the inner recursive function itself:

```markup
inner(root)
```

In this example, we have seen how using functions as first-class citizens can help us write recursive code. But there are performance implications of doing so. We’ll explore this in the next section.

Just Imagine

# Limits of recursive functions

Recursive functions have a performance penalty. When creating a recursive function call, we are copying over the state from one function stack to the next. This involves copying a lot of data into our working memory, but additional computational overhead is required to make the function call itself happen. The main limitation of solving problems recursively, at least in Go, is that we will eventually run out of space to make the recursive call happen. The other limitation is that a recursive solution is often slower than an iterative one.

## Measuring the performance of recursive versus iterative solutions

Before we look at the implications for the space our programs are using during recursive function calls, let’s compare the performance of recursive and iterative solutions that fit within our working memory. To demonstrate this, we will use the same iterative and recursive solution to the factorial problem that we saw at the start of this chapter:

```markup
package pkg
func IterativeFact(n int) int {
        result := 1
        for i := 2; i <= n; i++ {
                result *= i
        }
        return result
}
func RecursiveFact(n int) int {
        if n == 0 {
                return 1
        }
        return n * RecursiveFact(n-1)
}
```

To test both functions, we can use the benchmarking features of Go, which we explored in earlier chapters. The benchmark setup for both the iterative and recursive approach is straightforward:

```markup
package pkg
import "testing"
func BenchmarkIterative100(b *testing.B) {
        for n := 0; n < b.N; n++ {
                IterativeFact(10)
        }
}
func BenchmarkRecursive100(b *testing.B) {
        for n := 0; n < b.N; n++ {
                RecursiveFact(10)
        }
}
```

To benchmark the functions, we are going to generate the result of `Factorial(10)`. This is a pretty low number as it takes only 10 steps to derive the answer. Yet, the performance implications are clear. The average of multiple runs is as follows:

<table id="table001-2" class="No-Table-Style _idGenTablePara-1"><colgroup><col> <col></colgroup><tbody><tr class="No-Table-Style"><td class="No-Table-Style"><p><span class="No-Break">Function</span></p></td><td class="No-Table-Style"><p><span class="No-Break">ns/op</span></p></td></tr><tr class="No-Table-Style"><td class="No-Table-Style"><p><span class="No-Break">Iterative</span></p></td><td class="No-Table-Style"><p><span class="No-Break">8.2</span></p></td></tr><tr class="No-Table-Style"><td class="No-Table-Style"><p><span class="No-Break">Recursive</span></p></td><td class="No-Table-Style"><p><span class="No-Break">24.8</span></p></td></tr></tbody></table>

Table 7.1: Performance of iterative versus recursive functions in ns/op

As we can see, each iterative function needed about 1/4th the time to complete compared to the recursive function. The following graph shows the runtime of each function in ns/op for different inputs to the factorial function:

![Figure 7.3: Iterative (bottom) versus recursive (top) runtime in ns/op](https://static.packt-cdn.com/products/9781801811163/graphics/image/Figure_7.3_B18771.jpg)

Figure 7.3: Iterative (bottom) versus recursive (top) runtime in ns/op

The preceding graph shows that not only are recursive functions typically slower than their iterative counterparts, but they become slower in a more drastic way than the iterative solution. Keep these performance considerations in mind when opting to write recursive functions.

Note on benchmarking

These results were obtained using an Amazon Web Services EC2 instance (`t2.micro`) running Amazon Linux. The actual values of these results are machine-dependent. Running these benchmarks on a different machine will not necessarily give different results, but the general trend should remain the same. Running the benchmarks on the same `t2.micro` instance can still cause variations in the outcome.

## Space limitation of recursive functions

Apart from being slower in a typical scenario, recursive functions suffer from another drawback: each function called to a recursive function adds another frame to our stack. All the data from the current iteration is copied over and passed on to the new function. Recall from _Figure 7__.1_ that these stacks are added on top of each other in a **LIFO** fashion. Once our stack cannot grow any further, the program will halt. The good news is that in Go, this limit is relatively large and might not pose immediate practical problems. On a modern 64-bit machine, this stack can hold up to 1 GB of data, while on 32-bit machines, the limit is 250 MB.

In practice, the limits will eventually get hit. Let’s take a look at the following example:

```markup
func main() {
        infiniteCount(0)
}
func infiniteCount(i int) {
        if i%1000 == 0 {
                fmt.Println(i)
        }
        infiniteCount(i + 1)
}
```

If we were to run this function on a 32-bit machine, the tail end of the output would look like this:

```markup
1861000
1862000
1863000
1864000
runtime: goroutine stack exceeds 262144000-byte limit
runtime: sp=0xc008080380 stack=[0xc008080000, 0xc010080000]
fatal error: stack overflow
runtime stack:
runtime.throw({0x496535?, 0x50e900?})
        /usr/lib/golang/src/runtime/panic.go:992 +0x71
runtime.newstack()
        /usr/lib/golang/src/runtime/stack.go:1101 +0x5cc
runtime.morestack()
        /usr/lib/golang/src/runtime/asm_amd64.s:547 +0x8b
```

Hence, after about 1.8 million iterations, our program will crash. The actual limit depends on how large each stack frame is. For recursive functions that are more complex and manage more internal state, this limit will be lower. But what can we do to avoid hitting this limit? In Go, there is no way to completely avoid this limit when dealing with recursive functions. However, we can adjust the limit (although the 1 GB limit on a 64-bit machine should be plenty).

To alter the limit, we can use the `debug.SetMaxStack(bytes)` function. To demonstrate this, let’s alter the limits of a 32-bit machine to be twice the default size:

```markup
func main() {
        debug.SetMaxStack(262144000 * 2)
        infiniteCount(0)
}
func infiniteCount(i int) {
        if i%1000 == 0 {
                fmt.Println(i)
        }
        infiniteCount(i + 1)
}
```

Now, the function can go on much longer before running out of stack space:

```markup
3724000
3725000
3726000
3727000
3728000
runtime: goroutine stack exceeds 524288000-byte limit
runtime: sp=0xc010080388 stack=[0xc010080000, 0xc020080000]
fatal error: stack overflow
runtime stack:
runtime.throw({0x496535?, 0x50e900?})
        /usr/lib/golang/src/runtime/panic.go:992 +0x71
runtime.newstack()
        /usr/lib/golang/src/runtime/stack.go:1101 +0x5cc
runtime.morestack()
        /usr/lib/golang/src/runtime/asm_amd64.s:547 +0x8b
```

As we can tell, we could complete about 3.7 million iterations now before running into the limits of a 500 MB stack. While the 250 MB limit on a 32-bit machine is not extensive, for most practical applications, the 1-GB limit on a 64-bit machine should be sufficient.

## Tail recursion as a solution to stack limitations

Considering these limitations of recursive functions, it might seem strange that functional languages prefer recursion over iteration. Often, these languages, such as Haskell, only have recursion to work with, and they mock iterative functions. In this section, we will briefly look at how languages such as Haskell make recursion work.

Tip

The important thing to note here is that this is not possible in Go at the time of writing.

The technique some functional languages use is called **tail-call optimization**. Even non-functional languages might offer this – JavaScript is a notable example. This is a compiler (or interpreter) optimization whereby a recursive function call is made without allocating a new stack frame. Recall that the main drawback of recursive functions is the fact that they can run out of stack space – hence, if we solve that problem, we can have infinite recursion.

The compiler does need some help from the programmer to make this work. We’ll demonstrate the examples with Go, but keep in mind that so far in Go, the compiler performs no optimization and as such we would still overflow the stack eventually.

### Rewriting a recursive function into a tail-call recursive function

The key difference between a tail-call recursive function and a normal recursive function is that in the tail-call variant, each stack frame is independent of the others. To show this, let’s examine the factorial function again:

```markup
func Fact(input int) int {
    if input == 0 {
        return 1
    }
    return input * Fact(input-1)
}
```

In the last line of this function, we are returning `input * Fact(input – 1)`. This effectively ties the result of each call to the result of the subsequent call. To evaluate the multiplication, we’d first have to run the `Fact` function one level deeper. We could rewrite this function to avoid this and make each stack frame independent of the next.

To do this, let’s leverage our functions as first-class citizens again. We’ll create an outer function called `tailCallFactorial` that is non-recursive, which, in turn, calls an inner function called `factorial`, which is recursive.

To write this function recursively and decouple each stack frame, we’ll make two changes. First, we’ll use a counter that counts down from `input` to 0. This is equivalent to the `for i := n; i > 0; i—` `for` loop. Next, we’ll also keep aggregating the result of each multiplication. We will do this by performing multiplication on the input arguments of the next frame and passing on the multiplied values:

```markup
func tailCallFactorial(n int) int {
    var factorial func(counter, result int) int
    factorial = func(counter, result int) int {
        if counter == 0 {
            return result
        }
        return factorial(counter-1, result*counter)
    }
    return factorial(n, 1)
}
```

The key line of code that makes this function tail-call recursive is as follows:

```markup
return factorial(counter-1, result*counter)
```

With this simple change, each stack frame can be evaluated separately. And some compilers detect that the current stack frame can be de-allocated as soon as the next frame is called. This is a high-level overview of what tail-call optimization is, but keep in mind that Go does not perform such compiler optimizations at the time of writing.

Just Imagine

# Summary

In this chapter, we saw why recursion is a critical part of functional programming languages. We looked into how recursive functions make it easier to enforce function purity and immutability. Next, we saw how functions as first-class citizens can make it easier to manage the state of our recursive function calls. We did this by creating outer non-recursive functions that leverage an inner recursive function to perform the calculations.

After, we looked into the performance concerns of recursive and iterative solutions. Here, we saw that recursive solutions are often slower than their iterative counterparts and that eventually, recursive functions run out of memory to operate with, causing our programs to halt (even though this would take a very long time on a 64-bit machine).

Finally, we looked at Tail-Call optimization and Tail-Call recursive functions. Tail-Call optimization is a practical compiler optimization that many languages, such as Haskell and JavaScript, support to work around the limitations of recursive functions. Crucially, we have seen that Go does not support Tail-Call optimization, even if we write Tail-Call recursive functions.

In the next chapter, we will look at declarative and fluent programming. We’ll leverage recursion to write programs in a continuation-passing style.